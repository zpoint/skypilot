=== Job 1 (jupyter-notebook) on dev-bob ===
Job started at: 2024-01-13 08:00:00 UTC
Resources: 4CPU--16GB

Setting up development environment...
Installing dependencies...
pip install jupyter numpy pandas matplotlib seaborn scikit-learn plotly
Successfully installed jupyter-1.0.0 numpy-1.24.3 pandas-2.0.3 matplotlib-3.7.2 seaborn-0.12.2 scikit-learn-1.3.0 plotly-5.15.0

Starting Jupyter Notebook server...
jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser --allow-root

[I 08:00:15.123 NotebookApp] JupyterLab extension loaded from /opt/conda/lib/python3.10/site-packages/jupyterlab
[I 08:00:15.123 NotebookApp] JupyterLab application directory is /opt/conda/share/jupyter/lab
[I 08:00:15.125 NotebookApp] Serving notebooks from local directory: /home/gcpuser
[I 08:00:15.125 NotebookApp] Jupyter Notebook 6.5.4 is running at:
[I 08:00:15.125 NotebookApp] http://0.0.0.0:8888/?token=a7f3c9e8d4b2a1f6e5c3d7b9a8f4e2c1d6b5a9e7f3c8d4b2a1f6
[I 08:00:15.125 NotebookApp]  or http://127.0.0.1:8888/?token=a7f3c9e8d4b2a1f6e5c3d7b9a8f4e2c1d6b5a9e7f3c8d4b2a1f6
[I 08:00:15.125 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 08:00:15.125 NotebookApp] 
    
    To access the notebook, open this file in a browser:
        file:///home/gcpuser/.local/share/jupyter/runtime/nbserver-1-open.html
    Or copy and paste one of these URLs:
        http://0.0.0.0:8888/?token=a7f3c9e8d4b2a1f6e5c3d7b9a8f4e2c1d6b5a9e7f3c8d4b2a1f6
     or http://127.0.0.1:8888/?token=a7f3c9e8d4b2a1f6e5c3d7b9a8f4e2c1d6b5a9e7f3c8d4b2a1f6

[I 08:00:32.456 NotebookApp] Kernel started: 4f8a6b2c-1d3e-4f7a-9b2c-8e5d7f3a9b1c, session: data-exploration
[I 08:00:32.456 NotebookApp] Notebook opened: data_analysis.ipynb

=== Notebook Session Activity ===

[08:00:45] New notebook created: data_analysis.ipynb
[08:01:12] Cell 1 executed: Import statements
```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
```

[08:01:28] Cell 2 executed: Data generation
```python
# Generate sample dataset
X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, 
                          n_redundant=5, n_clusters_per_class=1, random_state=42)
feature_names = [f'feature_{i}' for i in range(20)]
df = pd.DataFrame(X, columns=feature_names)
df['target'] = y

print(f"Dataset shape: {df.shape}")
print(f"Target distribution:\n{df['target'].value_counts()}")
```
Output: Dataset shape: (1000, 21)
        Target distribution:
        0    500
        1    500
        Name: target, dtype: int64

[08:02:45] Cell 3 executed: Data exploration
```python
# Basic statistics
print("Dataset Info:")
print(df.info())
print("\nBasic Statistics:")
print(df.describe())
```

[08:03:12] Cell 4 executed: Visualization
```python
# Create correlation heatmap
plt.figure(figsize=(12, 8))
correlation_matrix = df.corr()
sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', center=0)
plt.title('Feature Correlation Heatmap')
plt.tight_layout()
plt.show()
```

[08:03:45] Cell 5 executed: Feature importance analysis
```python
# Train model to analyze feature importance
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Feature importance plot
feature_importance = pd.DataFrame({
    'feature': feature_names,
    'importance': rf_model.feature_importances_
}).sort_values('importance', ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(data=feature_importance.head(10), x='importance', y='feature')
plt.title('Top 10 Feature Importance')
plt.tight_layout()
plt.show()
```

[08:04:23] Cell 6 executed: Model evaluation
```python
# Model predictions and evaluation
y_pred = rf_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print(f"Model Accuracy: {accuracy:.4f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred))
```
Output: Model Accuracy: 0.9350
        Classification Report:
                     precision    recall  f1-score   support
        
                0       0.93      0.95      0.94       102
                1       0.94      0.92      0.93        98
        
         accuracy                           0.93       200
        macro avg       0.94      0.93      0.93       200
     weighted avg       0.94      0.93      0.93       200

[08:05:15] Cell 7 executed: Advanced visualization
```python
# Distribution plots
fig, axes = plt.subplots(2, 2, figsize=(12, 8))
axes = axes.ravel()

for i, feature in enumerate(feature_names[:4]):
    sns.histplot(data=df, x=feature, hue='target', ax=axes[i], alpha=0.7)
    axes[i].set_title(f'Distribution of {feature}')

plt.tight_layout()
plt.show()
```

[08:06:32] Cell 8 executed: Time series simulation
```python
# Create time series data for demonstration
dates = pd.date_range('2024-01-01', periods=100, freq='D')
values = np.cumsum(np.random.randn(100)) + 100
ts_df = pd.DataFrame({'date': dates, 'value': values})

plt.figure(figsize=(12, 6))
plt.plot(ts_df['date'], ts_df['value'], linewidth=2)
plt.title('Simulated Time Series Data')
plt.xlabel('Date')
plt.ylabel('Value')
plt.xticks(rotation=45)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```

[08:07:45] Cell 9 executed: Statistical analysis
```python
# Perform statistical tests
from scipy import stats

feature_0_class_0 = df[df['target'] == 0]['feature_0']
feature_0_class_1 = df[df['target'] == 1]['feature_0']

t_stat, p_value = stats.ttest_ind(feature_0_class_0, feature_0_class_1)
print(f"T-test results for feature_0:")
print(f"T-statistic: {t_stat:.4f}")
print(f"P-value: {p_value:.4f}")

if p_value < 0.05:
    print("Significant difference between classes")
else:
    print("No significant difference between classes")
```

[08:08:12] New notebook created: ml_experiments.ipynb
[08:08:45] Cell 1 executed: Hyperparameter tuning
```python
from sklearn.model_selection import GridSearchCV

# Hyperparameter grid
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 15],
    'min_samples_split': [2, 5, 10]
}

grid_search = GridSearchCV(RandomForestClassifier(random_state=42), 
                          param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)

print(f"Best parameters: {grid_search.best_params_}")
print(f"Best cross-validation score: {grid_search.best_score_:.4f}")
```

[08:15:23] Cell 2 executed: Model comparison
```python
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier

models = {
    'Random Forest': RandomForestClassifier(random_state=42),
    'Logistic Regression': LogisticRegression(random_state=42),
    'SVM': SVC(random_state=42),
    'Decision Tree': DecisionTreeClassifier(random_state=42)
}

results = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    results[name] = accuracy
    print(f"{name}: {accuracy:.4f}")
```

[08:22:15] Cell 3 executed: Results visualization
```python
# Plot model comparison
plt.figure(figsize=(10, 6))
models_df = pd.DataFrame(list(results.items()), columns=['Model', 'Accuracy'])
sns.barplot(data=models_df, x='Accuracy', y='Model')
plt.title('Model Comparison')
plt.xlabel('Accuracy')
plt.tight_layout()
plt.show()
```

[08:25:34] Notebook saved: data_analysis.ipynb
[08:25:35] Notebook saved: ml_experiments.ipynb

=== Session Summary ===

Active kernels: 2
- data-exploration (Python 3)
- ml-experiments (Python 3)

Notebooks created: 2
- data_analysis.ipynb (9 cells executed)
- ml_experiments.ipynb (3 cells executed)

Total cells executed: 12
Total execution time: 25 minutes 34 seconds

Libraries used:
- numpy: Data manipulation and mathematical operations
- pandas: Data analysis and manipulation
- matplotlib: Data visualization
- seaborn: Statistical data visualization
- scikit-learn: Machine learning algorithms and tools
- scipy: Scientific computing and statistics

Analysis completed:
✓ Data exploration and basic statistics
✓ Feature correlation analysis
✓ Machine learning model training
✓ Model evaluation and comparison
✓ Statistical hypothesis testing
✓ Time series visualization
✓ Hyperparameter tuning

Server still running - ready for more analysis...
Access notebook at: http://0.0.0.0:8888/?token=a7f3c9e8d4b2a1f6e5c3d7b9a8f4e2c1d6b5a9e7f3c8d4b2a1f6

Note: This is a development session in demo mode. 
